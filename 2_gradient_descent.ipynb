{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6f24bf-1c34-40a2-86a9-a5864117c48d",
   "metadata": {},
   "source": [
    "## 2. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b17f1f7-d186-415b-a527-4385730f6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do -> clean up, remove what I'm not using\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast, LlamaConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec82a4-6ce7-40f1-81cc-08fff2ad3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414d875-d738-414f-a821-139e0ed51b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e179b35-7e86-4503-a712-796615fd9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The capital of France is Paris\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d466e5-524f-460d-b42a-2f39f50c4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "\n",
    "my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "y_one_hot=F.one_hot(input_ids, num_classes=model.config.vocab_size)\n",
    "correct_next_token_probs = (my_probs[:,:-1]*y_one_hot[:,1:]).sum(-1) #I'm sure there's waaay more efficient ways to do this\n",
    "my_loss=-torch.log(correct_next_token_probs).mean()\n",
    "print(my_loss.item(), outputs.loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826dfc1d-fe96-4ac7-ba76-7adbc00989e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "\n",
    "my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "y_one_hot=F.one_hot(input_ids, num_classes=model.config.vocab_size)\n",
    "correct_next_token_probs = (my_probs[:,:-1]*y_one_hot[:,1:]).sum(-1) #I'm sure there's waaay more efficient ways to do this\n",
    "my_loss=-torch.log(correct_next_token_probs).mean()\n",
    "\n",
    "paris_only_loss=-np.log(my_probs[0, 5, 12366].item())\n",
    "print(my_loss.item(), outputs.loss.item(), paris_only_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff610ab-d916-4cfc-bbd3-a372fe0c2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa0dff-8f25-4595-80be-7cd8691678f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sI=np.argsort(my_probs[0,5, :].detach().cpu().float().numpy())[::-1]\n",
    "\n",
    "for i in sI[:10]:\n",
    "    print(i, round(my_probs[0, 5, i].item(),5), tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b2ca9-f8f4-4b43-95f9-1f3b4faac3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab057a2d-d7b1-481a-9633-ebc76b334b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120fe58-7ed0-45c5-b66a-370b9d437b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120ecf6-75f0-41a6-abee-9e905b11ffb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
